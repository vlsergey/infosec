\section{Расстояние единственности}\label{section_unicity_distance}
\selectlanguage{russian}
\index{расстояние единственности}

Использование ключей с длиной, сопоставимой с размером текста, имеет смысл только в очень редких случаях, когда есть возможность предварительно обменяться ключевой информацией большого объёма, много большего, чем планируемый объём передаваемой информации. Но в большинстве случаев использование абсолютно надёжных систем оказывается неэффективно как с экономической, так и с практической точек зрения. Если двум сторонам нужно постоянно обмениваться большим объёмом информации, и они смогли найти надёжный канал для передачи ключа, то ничего не мешает воспользоваться этим же каналом для передачи самой информации сопоставимого объёма.

В подавляющем большинстве криптосистем размер ключа много меньше размера открытого текста, который нужно передать. Попробуем оценить теоретическую надёжность подобных систем, исходя из статистических теоретико-информационных соображений.

В реальной ситуации длина ключа может быть много меньше длины открытого текста, поскольку передача ключа при больших объемах текста будет затруднена большим объемом ключа. Это означает, что энтропия ключа может быть  много меньше энтропии открытого текста: $H(K) \ll H(M)$. Для таких ситуаций важным понятием является \textbf{расстояние единственности}\index{расстояние единственности}, впервые предложенным в работах Клода Шеннона.~\cite{Golomb:2002, Schneier:2011}

\begin{definition}\label{definition:unicity_distance}
\textbf{Расстоянием единственности} называется количество символов шифротекста, которое необходимо для однозначного восстановления открытого текста.
\end{definition}

Пусть зашифрованное сообщение (шифротекст) $C$ состоит из $N$ символов алфавита, состоящего из $L$ букв:
	\[C = (C_1, C_2, \dots, C_N).\]

Определим функцию $h(n)$ как условную энтропию ключа при перехвате криптоаналитиком $n$ символов шифротекста:
\[ \begin{array}{l}
    h ( 0 ) = H(K), \\
    h ( 1 ) = H(K | C_1), \\
    h ( 2 ) = H(K | C_1, C_2), \\
    \dots \\
    h ( n ) = H(K | C_1, C_2, \dots, C_n), \\
    \dots
\end{array} \]

Функция $h(n)$ называется \emph{функцией неопределённости ключа}\index{функция!неопределённости ключа}. Она является невозрастающей функцией числа перехваченных символов $n$. Если для некоторого значения $n_u$ окажется, что $h ( n_u ) = 0$, то это будет означать, что ключ $K$ является детерминированной функцией первых $n_u$ символов шифротекста $C_1, C_2, \dots, C_{n_u}$, и, при неограниченных вычислительных возможностях, используемый ключ $K$ может быть определён. Число $n_u$ и будет являться \emph{расстоянием единственности}. Полученное $n_u$ соответствует определению~\ref{definition:unicity_distance}, так как для корректной криптосистемы однозначное определение ключа также означает и возможность получить открытый текст однозначным способом.

Найдем типичное поведение функции $h(n)$ и значение расстояния единственности $n_u$. Используем следующие предположения.
\begin{itemize}
    \item Криптограф всегда стремится спроектировать систему таким образом, чтобы символы шифрованного текста имели равномерное распределение и, следовательно, энтропия шифротекста имела максимальное значение:
            \[ H(C_1 C_2 \dots C_n) \approx n \log_2 L, ~ n = 1, 2, \dots, N. \]
    \item Имеет место соотношение
            \[ H(C | K) = H(C_1 C_2 \dots C_N | K)  =  H(M), \]
        которое следует из цепочки равенств
            \[ H(MCK) = H(M) + H(K | M) + H(C | MK) = H(M) + H(K), \]
        так как
            \[ H(K | M) = H(K), ~~ H(C | MK) = 0, \]
            \[H(MCK) = H(K) + H(C | K) + H(M | CK) = H(K) + H(C | K), \]
        поскольку
            \[ H(M | CK) = 0. \]
    \item Предполагается, что для любого $n \le N$ приближенно выполняется соотношение
        \[ H(C_n | K) \approx \frac{1}{N} H(M), \]
        \[ H(C_1 C_2\dots C_n | K) \approx \frac{n}{N} H(M). \]
\end{itemize}

Вычислим энтропию $H(C_1 C_2 \dots C_n ; K)$ двумя способами:
    \[ H( C_1 C_2 \dots C_n ; K ) = H(C_1 C_2 \dots C_n) + H(K | C_1 C_2 \dots C_n) \approx \]
        \[ \approx n \log_2 L + h(n), \]
    \[ H( C_1 C_2 \dots C_n ; K ) = H(K) + H(C_1 C_2 \dots C_n | K) \approx \]
        \[ \approx H(K) + \frac{n}{N} H(M). \]

Отсюда следует, что
    \[ h(n) \approx H(K) + n \left( \frac{H(M)}{N} - \log_2 L \right) \]
и
    \[ n_u = \frac{H(K)}{ \left( 1 - \frac{H(M)}{N \log_2 L} \right) \log_2 L} = \frac{H(K)}{\rho \log_2 L}. \]
Здесь
    \[ \rho = 1 - \frac{H(M)}{N \log_2 L} \]
означает избыточность источника открытых текстов.

Если избыточность источника измеряется в битах на символ, ключ шифрования выбирается случайным образом из всего множества ключей $\{0, 1\}^{l_K}$, где $l_K$ -- длина ключа в битах, и расстояние единственности $n$ также получается в битах, то формула значительно упрощается:

\begin{equation}\label{eq:unicity_distance_simple_frac}
n_u \approx \frac{l_K}{\rho}.
\end{equation}

Взяв нижнюю границу $H(M)$ энтропии одного символа английского текста как $1{,}3$ бит/символ~\cite{Shannon:1951, Schneier:2002}, получим:

	\[ \rho _{en} \approx 1 - \frac{ 1{,}3 }{ \log _2 {26} } \approx 0{,}72.\]

Для русского текста с энтропией $H(M)$ примерно равной $3{,}01$ бит/символ~\cite{Lebedev:1958}\footnote{Следует отметить, что для английского текста значение $1{,}3$ представляет собой суммарную оценку для всего текста, в то время как оценка $3{,}01$ для русского текста получена Лебедевым и Гармашем из анализа \textbf{частот трёхбуквенных сочетаний} в отрывке текста Л. Н. Толстого <<Война и мир>> длиной в 30 тыс. символов. Соответствующая оценка для английского текста, также приведённая в работе Шеннона, примерно равна $3{,}0$} получаем:

	\[ \rho _{ru} \approx 1 - \frac{ 3{,}0 }{ \log _2 {32} } \approx 0{,}40.\]

Однако, если предположить, что текст передаётся в формате простого текстового файла (plain text) в стандартной кодировке UTF-8 (один байт на английский символ и два -- на кириллицу), то значения избыточности становятся примерно равны $0{,}83$ для английского и $0{,}81$ для русского языков.

	\[ \rho _{en, UTF-8} \approx 1 - \frac{ 1{,}3 }{ \log _2 {2^{8}} } \approx 0{,}83,\]
	\[ \rho _{ru, UTF-8} \approx 1 - \frac{ 3{,}0 }{ \log _2 {2^{16}} } \approx 0{,}81.\]

Подставляя полученные числа в выражение~\ref{eq:unicity_distance_simple_frac} для шифров DES и AES, получаем таблицу \ref{table:unicity_distances}.

\begin{table}[!ht]
	\centering
		\begin{tabular}{|| l | r | r ||}
			\hline
			\hline
			\text{Блочный шифр} & \text{Английский текст} & \text{Русский текст} \\
			\hline
			\hline
			\text{Шифр DES\index{шифр!DES},} & \text{ $\approx~67$ бит;} & \text{$\approx~69$ бит;} \\
			\text{ключ 56 бит} & \text{ 2 блока данных} & \text{2 блока данных} \\
			\hline
			\text{Шифр AES\index{шифр!AES},} & \text{ $\approx~153$ бит;} & \text{$\approx~158$ бит;} \\
			\text{ключ 128 бит} & \text{ 3 блока данных} & \text{3 блока данных} \\
			\hline
			\hline
		\end{tabular}
  \caption{Расстояния единственности для шифров DES и AES для английского и русского текста в формате простого текстового файла и кодировке UTF-8}
	\label{table:unicity_distances}
\end{table}

Полученные данные с теоретической точки зрения означают, что когда криптоаналитик будет подбирать ключ к зашифрованным данным, трёх блоков данных ему будет достаточно, чтобы сделать вывод о правильности выбора ключа расшифрования и корректности дешифровки, если известно, что в качестве открытого текста выступает простой текстовый файл. Если открытым текстом является случайный набор данных, то криптоаналитик не сможет отличить правильно расшифрованный набор данных от неправильного, и расстояние единственности, в соответствии с выводами выше (для нулевой избыточности источника), оказывается равным бесконечности.

Улучшить ситуацию для легального пользователя помогает предварительное сжатие открытого текста с помощью алгоритмов архивации, что уменьшает его избыточность (а также уменьшает размер и ускоряет процесс шифрования в целом). Однако расстояние единственности не становится нулевым, так как в результате работы алгоритмов архивации присутствуют различные константные сигнатуры, а для многих текстов можно заранее предсказать примерные словари сжатия, которые будут записаны как часть открытого текста. Более того, используемые на практике программы безопасной передачи данных вынуждены так или иначе встраивать механизмы хотя бы частичной быстрой проверки правильности ключа расшифрования (например, добавлением известной сигнатуры в начало открытого текста). Делается это для того, чтобы сообщить легальному получателю об ошибке ввода ключа, если такая ошибка случится.

Соображения выше показывают, что для одного ключа расшифрования так или иначе процедура проверки его корректности является быстрой. Чтобы значительно усложнить работу криптоаналитику, множество ключей, которые требуется перебрать, должно быть большой величиной (например, от $2^{80}$). Это можно сделать, во-первых увеличением битовой длины ключа, во-вторых, аккуратной разработкой алгоритма шифрования, чтобы криптоаналитик не смог <<отбросить>> часть ключей без их полной проверки.

Несмотря на то, что теоретический вывод о совершенной криптостойкости для практики неприемлем, так как требует большого объема ключа, сравнимого с объемом открытого текста, разработанные идеи находят успешное применение в современных криптосистемах. Вытекающий из идей Шеннона принцип выравнивания апостериорного распределения символов в шифротекстах используется в современных криптосистемах с помощью многократных итераций, включающих замены и перестановки.
